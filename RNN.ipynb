{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Io8NXQv_M5vsfZOuaTsms5sbMpNtp8SH","authorship_tag":"ABX9TyN3Trq5a0PJ8yCPYDYCjb3W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TBeulrl5j8yq"},"source":["# リカレンとニューラルネットワーク"]},{"cell_type":"markdown","metadata":{"id":"PKgsntRZj8aO"},"source":["## 【問題1】SimpleRNNのフォワードプロパゲーション実装"]},{"cell_type":"markdown","metadata":{"id":"WpRNj18gobui"},"source":["SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n","\n","\n","フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n","\n","\n","バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。"]},{"cell_type":"markdown","metadata":{"id":"4XlKIYZlobjR"},"source":["$$\n","a_t=x_t⋅W_x+h_{t−1}⋅W_h+B\n","$$\n","$$\n","h_t=tanh(a_t)\n","$$\n","\n","$a_t$ : 時刻tの活性化関数を通す前の状態 (batch_size, n_nodes)\n","\n","\n","$h_t$ : 時刻tの状態・出力 (batch_size, n_nodes)\n","\n","\n","$x_{t}$ : 時刻tの入力 (batch_size, n_features)\n","\n","\n","$W_{x}$ : 入力に対する重み (n_features, n_nodes)\n","\n","\n","$h_{t-1}$ : 時刻t-1の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)\n","\n","\n","$W_{h}$ : 状態に対する重み。 (n_nodes, n_nodes)\n","\n","\n","$B$ : バイアス項 (n_nodes,)\n","\n","\n","初期状態 $h_{0}$ はすべて0とすることが多いですが、任意の値を与えることも可能です。"]},{"cell_type":"markdown","metadata":{"id":"14JeXpOFpQ1Z"},"source":["上記の処理を系列数n_sequences回繰り返すことになります。RNN全体への入力 $x$ は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していきます。\n","\n","\n","分類問題であれば、それぞれの時刻のhに対して全結合層とソフトマックス関数（またはシグモイド関数）を使用します。タスクによっては最後の時刻のhだけを使用することもあります。"]},{"cell_type":"code","metadata":{"id":"7JHLhQGQi5YF"},"source":["class SimpleRNN:      \n","    def forward(self, X,h):\n","        \"\"\"順伝播\n","        Parameters\n","        ----------\n","        X : 時刻の入力\n","        h : 時刻t-1の状態\n","        \"\"\"\n","\n","        # 系列数分繰り返す\n","        for n in range(n_sequences):\n","          h = np.tanh(x[:,n,:] @ w_x + h @ w_h + b)\n","\n","        return h"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_31sOM6s49q"},"source":["## 【問題2】小さな配列でのフォワードプロパゲーションの実験"]},{"cell_type":"markdown","metadata":{"id":"5bz389V-tFa0"},"source":["小さな配列でフォワードプロパゲーションを考えてみます。\n","\n","\n","入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n","\n","\n","ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。\n","\n"]},{"cell_type":"code","metadata":{"id":"fPJLe3GJnVfo"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH7mCo1ttIiJ"},"source":["# (1,3,2)\n","x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n","# (2,4)\n","w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n","# (4,4)\n","w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n","# (1)\n","batch_size = x.shape[0] # 1\n","# (3)\n","n_sequences = x.shape[1] # 3\n","# (2)\n","n_features = x.shape[2] # 2\n","# (4)\n","n_nodes = w_x.shape[1] # 4\n","# (1,4)\n","h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n","# (4,)\n","b = np.array([1, 1, 1, 1]) # (n_nodes,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flhdJlPunbx4"},"source":["# インスタンスの生成\n","srnn = SimpleRNN()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79agWPVfpLYA"},"source":["# インスタンス化\n","ans = srnn.forward(x,h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zP7p79_NpU_p","executionInfo":{"status":"ok","timestamp":1631846757897,"user_tz":-540,"elapsed":245,"user":{"displayName":"daisuke sato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsUCgSev-4ixGqCWaINvF6Uos2LcjnmbactKz4Jw=s64","userId":"14049008022944333621"}},"outputId":"314f86a0-8de0-4d07-94eb-4e5070d96782"},"source":["# 確認\n","print(ans)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"]}]}]}